{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from pdf2image import convert_from_path\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../dataset/pdf\"\n",
    "IMAGE_PATH = \"../dataset/image\"\n",
    "\n",
    "# Set plot size\n",
    "plt.rcParams[\"figure.figsize\"] = 15, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion from PDF to PNG (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for filepath in tqdm(listdir(PDF_PATH)):\n",
    "    images = convert_from_path(''.join([PDF_PATH, '/', filepath]))\n",
    "    filename = filepath.split('.')[0]\n",
    "    makedirs(''.join([IMAGE_PATH, '/', filename]))\n",
    "    for index, image in enumerate(images):\n",
    "        image.save(''.join([IMAGE_PATH, '/', filename, '/', str(index), '.png']), 'PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filenames = glob(''.join([IMAGE_PATH, '/*/*.png']))\n",
    "filenames.sort()\n",
    "image = cv.imread(filenames[62], cv.IMREAD_GRAYSCALE)\n",
    "plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization (Otsu Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold, binarized = cv.threshold(image, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "plt.imshow(cv.cvtColor(binarized, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization (Bernsen Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aperture_size = 3\n",
    "contrast_limit = 10\n",
    "\n",
    "offset = int(aperture_size / 2)\n",
    "global_threshold = cv.threshold(image, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[0]\n",
    "print(f'Threshold Value: {global_threshold}')\n",
    "not_image = cv.bitwise_not(image)\n",
    "x, y = not_image.nonzero()\n",
    "vals = image[x, y]\n",
    "coors = tuple([x, y] for x, y in zip(x, y))\n",
    "for coor in coors:\n",
    "    aperture = np.copy(not_image[coor[0] - offset : coor[0] + offset + 1, coor[1] - offset : coor[1] + offset + 1])\n",
    "    if aperture.size != 0: #\n",
    "        contrast = abs(aperture.max() - aperture.min())\n",
    "        if contrast > contrast_limit:\n",
    "            threshold = int(aperture.max() + aperture.min() / 2)\n",
    "        else: \n",
    "            threshold = global_threshold\n",
    "        not_image[coor[0], coor[1]] = 0 if not_image[coor[0], coor[1]] < threshold else 255\n",
    "    \n",
    "plt.imshow(cv.cvtColor(cv.bitwise_not(not_image), cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skew correction (Hough Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cannied = cv.Canny(binarized, 50, 200, None, 3)\n",
    "underlay = np.copy(image)\n",
    "\n",
    "# For ease of view\n",
    "distance_resolution = 1\n",
    "angle_resolution = np.pi / 180\n",
    "vote_threshold = 180\n",
    "lines = cv.HoughLines(cannied, distance_resolution, angle_resolution, vote_threshold)\n",
    "skew_angles = []\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        rho = line[0][0]\n",
    "        theta = line[0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "        cv.line(underlay, pt1, pt2, (0, 0, 0), 3, cv.LINE_AA)\n",
    "           \n",
    "        # Assumption that the image is already in protrait with skew angle < 45\n",
    "        # Get only horizontal lines (i.e Lines with |angle| < 45 from horizontal)\n",
    "        # Getting other angle of right angled triangle thereby retrieving the deviation angle via congruent alternate internal angles\n",
    "        dev_from_hrzntal_in_rad = np.pi / 2 - theta \n",
    "        \n",
    "        # Conversion to deg\n",
    "        dev_from_hrzntal_in_deg = dev_from_hrzntal_in_rad / np.pi * 180\n",
    "        \n",
    "        # Assuming dataset skew angle < 10\n",
    "        if (abs(dev_from_hrzntal_in_deg) < 10):\n",
    "            skew_angles.append(dev_from_hrzntal_in_deg)\n",
    "        \n",
    "# Get average of all horizontal lines angle only\n",
    "# print(f'All deviation angles: {skew_angles}')\n",
    "print(f'Number of lines: {len(lines)}')\n",
    "\n",
    "deskew_angle = sum(skew_angles) / len(skew_angles)\n",
    "print(f'Deskew Angle: {deskew_angle}')\n",
    "\n",
    "\n",
    "#plt.imshow(cv.bitwise_not(underlay), cmap=\"gray\")\n",
    "plt.imshow(cv.cvtColor(underlay, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deskewed_image = ndimage.rotate(binarized, -deskew_angle)\n",
    "plt.imshow(cv.cvtColor(deskewed_image, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aperture_size = 5\n",
    "denoised_image = cv.medianBlur(deskewed_image, aperture_size)\n",
    "plt.imshow(cv.cvtColor(denoised_image, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoning (Grow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Bounding Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv.cvtColor(denoised_image, cv.COLOR_BGR2RGB))\n",
    "underlay = np.copy(denoised_image)\n",
    "\n",
    "contours, hier = cv.findContours(cv.bitwise_not(denoised_image), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "rects = []\n",
    "for c in contours:\n",
    "    x, y, w, h = cv.boundingRect(c)\n",
    "    rects.append((x, y, w, h))\n",
    "    cv.rectangle(underlay, (x, y), (x + w, y + h), 0, 1)\n",
    "    \n",
    "# Sort by x coor\n",
    "rects.sort(key = lambda x: x[0])\n",
    "# For removing encapsulating box if there is\n",
    "rects = list(filter(lambda x: x[0] >= 50 and x[1] >= 50, rects))\n",
    "plt.imshow(cv.cvtColor(underlay, cv.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Bounding Rects after Growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow(arr, initial_rects, iteration):\n",
    "    rects = copy.deepcopy(initial_rects)\n",
    "    \n",
    "   \n",
    "    x_thresh = 50\n",
    "    y_diff = 50\n",
    "\n",
    "    final_rects = []\n",
    "\n",
    "    for i in range(iteration):\n",
    "        if len(final_rects) != 0:\n",
    "            rects = copy.deepcopy(final_rects) \n",
    "        underlay = np.copy(denoised_image)\n",
    "\n",
    "        used_rects = [False for rect in rects] \n",
    "        final_rects = []\n",
    "        for index, rect in enumerate(rects):\n",
    "            if (used_rects[index] == False):\n",
    "                current_left = rect[0]\n",
    "                # x + width\n",
    "                current_right = rect[0] + rect[2]\n",
    "        \n",
    "                current_top = rect[1]\n",
    "                # y + height\n",
    "                current_bottom = rect[1] + rect[3]\n",
    "\n",
    "                used_rects[index] = True\n",
    "        \n",
    "                # All other rects\n",
    "                for internal_index, other_rect in enumerate(rects[(index + 1):], start = (index + 1)):\n",
    "                    \n",
    "                    other_left = other_rect[0]\n",
    "                    other_right = other_rect[0] + other_rect[2]\n",
    "                    other_top = other_rect[1]\n",
    "                    other_bottom = other_rect[1] + other_rect[3]\n",
    "                    if ((other_left <= current_right + x_thresh) and (abs(current_top - other_top) <= y_diff or abs(current_bottom - other_bottom) <= y_diff)):\n",
    "                        current_right = other_right\n",
    "                        current_top = min(current_top, other_top)\n",
    "                        current_bottom = max(current_bottom, current_bottom)\n",
    "                        used_rects[internal_index] = True\n",
    "\n",
    "                final_rects.append([current_left, current_top, current_right - current_left, current_bottom - current_top])\n",
    "        for rect in final_rects:\n",
    "            cv.rectangle(underlay, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), 0, -1)\n",
    "        arr[i].imshow(cv.cvtColor(underlay, cv.COLOR_BGR2RGB))\n",
    "    return final_rects\n",
    "    \n",
    "underlay = np.copy(denoised_image)\n",
    "temp = grow(arr[0], rects, 1)\n",
    "for rect in temp:\n",
    "    cv.rectangle(underlay, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), 0, -1)\n",
    "\n",
    "plt.imshow(cv.cvtColor(underlay, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoning (Left Detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Number Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_rects = copy.deepcopy(rects)\n",
    "\n",
    "lowest_x = min(x for (x,y,w,h) in temp_rects if w > 10 and h > 10)\n",
    "question_num_idx = temp_rects.index([rect for rect in temp_rects if lowest_x in rect][0])\n",
    "left_most_rect = temp_rects[question_num_idx]\n",
    "print(f' Left most rect: {left_most_rect}')\n",
    "del temp_rects[question_num_idx]\n",
    "question_num_rects = [left_most_rect]\n",
    "while(True):\n",
    "    next_lowest_x = min(x for (x,y,w,h) in temp_rects if w > 10 and h > 10)\n",
    "    next_left_most_rect_idx = temp_rects.index([rect for rect in temp_rects if next_lowest_x in rect][0])\n",
    "    next_left_most_rect = temp_rects[next_left_most_rect_idx]\n",
    "    print(f' Next left most rect: {next_left_most_rect}')\n",
    "    if next_left_most_rect[0] - left_most_rect[0] <= 15:\n",
    "        del temp_rects[next_left_most_rect_idx]\n",
    "        question_num_rects.append(next_left_most_rect)\n",
    "    else:\n",
    "        break;\n",
    "        \n",
    "underlay = np.copy(denoised_image)\n",
    "print(question_num_rects)\n",
    "for rect in question_num_rects:\n",
    "    cv.rectangle(underlay, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), 0, -1)\n",
    "\n",
    "plt.imshow(cv.cvtColor(underlay, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "padding = 8\n",
    "underlay = np.copy(denoised_image)\n",
    "crop_base = np.copy(denoised_image)\n",
    "temp_rects = copy.deepcopy(rects)\n",
    "highest_x = max(x+w for (x,y,w,h) in temp_rects)\n",
    "highest_y = max(y+h for (x,y,w,h) in temp_rects)\n",
    "question_num_rects.sort(key = lambda x: x[1])\n",
    "question_crops = []\n",
    "for idx, question_num_rect in enumerate(question_num_rects):\n",
    "    try:\n",
    "        next_rect = question_num_rects[idx+1]\n",
    "    except Exception as e:\n",
    "        print(f'Error message: {e}')\n",
    "        cv.rectangle(underlay, (question_num_rect[0] - padding, (question_num_rect[1] - padding)), \n",
    "                 (highest_x, highest_y), 0, 1)\n",
    "        question_crops.append(crop_base[(question_num_rect[1] - padding):highest_y, (question_num_rect[0] - padding):highest_x])\n",
    "        break;\n",
    "        \n",
    "    cv.rectangle(underlay, (question_num_rect[0] - padding, question_num_rect[1] - padding), \n",
    "            (highest_x, next_rect[1] + padding), 0, 1)\n",
    "    question_crops.append(crop_base[(question_num_rect[1] - padding):(next_rect[1] + padding), (question_num_rect[0] - padding):highest_x])\n",
    "         \n",
    "        \n",
    "plt.imshow(cv.cvtColor(underlay, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv.cvtColor(question_crops[0], cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytesseract temporary recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pytesseract.image_to_string(question_crops[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnseeker-ocr",
   "language": "python",
   "name": "learnseeker-ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
